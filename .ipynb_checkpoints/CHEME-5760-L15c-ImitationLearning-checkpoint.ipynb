{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cf0cda5-150b-43ff-a07c-3b21c659c460",
   "metadata": {},
   "source": [
    "# Lab 15c: Learning an Optimal Trading Policy\n",
    "As part of the `CHEME 5660 Quantitative Finance` course, we constructed an `expert` agent who reallocates their portfolio daily by solving the Minimum Variance portfolio allocation problem everyday, using new information generated during that trading day. We've recorded the policy of this `expert` and proposed copying it using a deep learning model. \n",
    "\n",
    "* Our strategy is an example of `Imitation Learning,` and particularly `Behavioral cloning.` We copy what an expert does by watching them. For more information on this idea, [check out CS273b from Stanford](https://web.stanford.edu/class/cs237b/). \n",
    "* Let's implement the `policy` function $\\pi(s)$ as a dictionary that stores a `state tuple s` as its `keys` and action vector $a$ as the value. Let's keep this in the `policy` variable\n",
    "* We'll store a separate collection of the `states` and the `actions` so we can explore `policy.` In both cases, we'll also implement these as dictionaries\n",
    "\n",
    "The objective of this lab is to familarize students with constructing, and training artifical neural network (ANN) models of and some of the various conventions used in the application area.\n",
    "\n",
    "## Tasks\n",
    "* __Prerequisite__: Load policy, states and actions of the `expert` trader\n",
    "* __Task 1__: Build `training` dataset from the `expert` policy\n",
    "* __Task 2__: Build a Deep Learning model of the `expert` policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c776a66-cd3e-409e-94d4-ac432d6d751e",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ab15b84-ed1e-498a-b95f-e7aaf8ef85aa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m git-repo `https://github.com/varnerlab/VLDecisionsPackage.jl.git`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/Desktop/julia_work/CHEME-5760-Labs-F23/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/Desktop/julia_work/CHEME-5760-Labs-F23/Manifest.toml`\n",
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m git-repo `https://github.com/varnerlab/VLQuantitativeFinancePackage.jl.git`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/Desktop/julia_work/CHEME-5760-Labs-F23/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/Desktop/julia_work/CHEME-5760-Labs-F23/Manifest.toml`\n",
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `~/Desktop/julia_work/CHEME-5760-Labs-F23`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/Desktop/julia_work/CHEME-5760-Labs-F23/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/Desktop/julia_work/CHEME-5760-Labs-F23/Manifest.toml`\n",
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m registry at `~/.julia/registries/General.toml`\n",
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m git-repo `https://github.com/varnerlab/VLDecisionsPackage.jl.git`\n",
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m git-repo `https://github.com/varnerlab/VLQuantitativeFinancePackage.jl.git`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/Desktop/julia_work/CHEME-5760-Labs-F23/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/Desktop/julia_work/CHEME-5760-Labs-F23/Manifest.toml`\n"
     ]
    }
   ],
   "source": [
    "include(\"Include.jl\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a67dfa-a647-4781-a1d4-144074c1d915",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Prerequisite: Load policy, states and actions of the `expert` trader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "455eeac4-0d34-48f0-90f5-bf6cb9b736eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = load(joinpath(_PATH_TO_DATA, \"PolicyData-Testing-MinVar-Agent.jld2\"));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dac79b3f-2951-46ea-be5f-807a17b62263",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "states = dataset[\"states\"];\n",
    "actions = dataset[\"actions\"];\n",
    "policy = dataset[\"policy\"];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca36c337-10d2-491a-9e1c-c9009ffd51a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([4.9900842162455845, 5.152445652173913, 0.3092524377031419, 0.0, 0.0, 1.0049838661568913], [-0.01701574822598631, 0.1935452534460845, 0.47009619391386487, 0.2594984882083575, 0.11867979037912248, 0.15587517810289664])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82a212a0-da57-482f-a7d3-a25d5ba1350c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3×6 OneHotMatrix(::Vector{UInt32}) with eltype Bool:\n",
       " ⋅  1  1  1  ⋅  ⋅\n",
       " 1  ⋅  ⋅  ⋅  ⋅  1\n",
       " ⋅  ⋅  ⋅  ⋅  1  ⋅"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50aafc0e-559b-4e43-8a56-998821e7c372",
   "metadata": {},
   "source": [
    "## Task 1: Build `training` dataset from the `expert` policy\n",
    "Let's try to use [Deep Learning](https://www.deeplearningbook.org) to compute a policy function $\\pi_{\\theta}(s)$ using the [Flux.jl](https://fluxml.ai) machine learning package (loaded by the `Include.jl` file). First, let's build a `training` dataset from the `policy` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2bea149-3eef-4e64-863c-d2ef04126d89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# initialize storage for labeled data for training -\n",
    "training_dataset = Vector{Tuple{Vector{Float32}, OneHotVector{UInt32}}}()\n",
    "number_of_training_examples = length(states);\n",
    "ticker_index = 6; # let's look at SPY\n",
    "for i ∈ 1:number_of_training_examples\n",
    "    \n",
    "    state = states[i];\n",
    "    action = actions[i];\n",
    "    single_state_vector = [state[1]...,state[2]...]\n",
    "    action_vector = action[:, ticker_index];\n",
    "    \n",
    "    # make a training tuple -\n",
    "    training_tuple = (\n",
    "        single_state_vector, action_vector\n",
    "    );\n",
    "    \n",
    "    # insert -\n",
    "    push!(training_dataset, training_tuple);\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5e865d4-325b-4e28-91d1-09b41c25477b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12-element Vector{Float32}:\n",
       "  4.990084\n",
       "  5.152446\n",
       "  0.30925244\n",
       "  0.0\n",
       "  0.0\n",
       "  1.0049839\n",
       " -0.017015748\n",
       "  0.19354525\n",
       "  0.4700962\n",
       "  0.25949848\n",
       "  0.11867979\n",
       "  0.15587518"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_dataset[1][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b9061f-0020-4f47-b6c9-27f2ef3d3e7b",
   "metadata": {},
   "source": [
    "## Task 2: Build a Deep Learning model of the `expert` policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9dd831e-c878-4277-b267-7d2721964827",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "number_of_input_states = length(training_dataset[1][1]);\n",
    "number_of_classes = 3; # we have buy, sell and hold\n",
    "number_of_nodes = 48;\n",
    "FFN_policy_model = Chain(Dense(number_of_input_states, number_of_nodes, σ), \n",
    "    Dense(number_of_nodes, number_of_nodes, σ), Dense(number_of_nodes, 3, σ), NNlib.softmax);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27df5340-cfb9-4c0d-8afb-072f00b98d8f",
   "metadata": {},
   "source": [
    "For the loss function $L(\\theta)$, we'll use a version of the [cross entropy function](https://en.wikipedia.org/wiki/Cross-entropy), where the training examples $\\hat{y}_{i}$ are encoded in [one-hot format](https://en.wikipedia.org/wiki/One-hot):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a181823d-e513-445d-b63a-4a03440a273c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# setup a loss function -\n",
    "loss(x, y) = Flux.Losses.logitbinarycrossentropy(FFN_policy_model(x), y; agg = mean);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b585c7c1-ec64-4ffd-836c-b918b90786ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pointer to params -\n",
    "θ = Flux.params(FFN_policy_model);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaebd7e6-6e6e-4833-b80d-a34a0dba57a7",
   "metadata": {},
   "source": [
    "Next, let's specify the optimization approach the we'll use to estimate the unknown model parameters $\\theta$. In particular, we'll use the [Momentum gradient descent algorithm](https://optimization.cbe.cornell.edu/index.php?title=Momentum): \n",
    "> Momentum is an extension to the gradient descent optimization algorithm that allows the search to build inertia in a direction in the search space and overcome the oscillations of noisy gradients and coast across flat spots of the search space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8d0b98d-9923-48a5-8c51-5c477fece4cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "λ = 0.01;  # learning rate\n",
    "β = 0.05; # momentum parameter\n",
    "# opt = Momentum(λ, β);\n",
    "opt = AdaDelta();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec5133e-8a4a-4ba0-986a-d091bcc67d3d",
   "metadata": {},
   "source": [
    "We'll specify the number of times we process the data (called an `epoch`) in the `number_of_epochs` variable. To run the gradient descent estimation algorithm, we'll call the `train!(...)` function exported by the [Flux.jl](https://fluxml.ai) package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e6ad0983-5377-43c8-8fd9-dbe083c5b28b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss(test_x, test_y) = 0.777251f0\n",
      "loss(test_x, test_y) = 0.8062558f0\n",
      "loss(test_x, test_y) = 0.80365986f0\n",
      "loss(test_x, test_y) = 0.8039484f0\n",
      "loss(test_x, test_y) = 0.8050162f0\n",
      "loss(test_x, test_y) = 0.79285717f0\n",
      "loss(test_x, test_y) = 0.7682772f0\n",
      "loss(test_x, test_y) = 0.7553499f0\n"
     ]
    }
   ],
   "source": [
    "test_x, test_y = training_dataset[1][1], training_dataset[1][2]\n",
    "number_of_epochs = 2000;\n",
    "evalcb() = @show(loss(test_x, test_y))\n",
    "throttled_cb = Flux.throttle(evalcb, 5)\n",
    "for i = 1:number_of_epochs\n",
    "    Flux.train!(loss, θ, training_dataset, opt, cb = throttled_cb)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93175bae-bd6e-4221-bcfa-9a440f074879",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "correct_counter = 0;\n",
    "for i ∈ 1:number_of_training_examples\n",
    "    \n",
    "    single_state_vector = [states[i][1]...,states[i][2]...] .|> x-> convert(Float32,x)\n",
    "    ŷ = FFN_policy_model(single_state_vector);\n",
    "    y = actions[i][:,ticker_index];\n",
    "    \n",
    "    if (argmax(ŷ) == argmax(y))\n",
    "        correct_counter += 1\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "69c6b54a-4467-417c-96f8-6c72bcd021a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6121883656509696"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_counter/number_of_training_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c21fdd7-eacd-4001-9299-c2d5a67a1f52",
   "metadata": {},
   "source": [
    "## Disclaimer and Risks\n",
    "__This content is offered solely for training and  informational purposes__. No offer or solicitation to buy or sell securities or derivative products, or any investment or trading advice or strategy,  is made, given, or endorsed by the teaching team. \n",
    "\n",
    "__Trading involves risk__. Carefully review your financial situation before investing in securities, futures contracts, options, or commodity interests. Past performance, whether actual or indicated by historical tests of strategies, is no guarantee of future performance or success. Trading is generally inappropriate for someone with limited resources, investment or trading experience, or a low-risk tolerance.  Only risk capital that is not required for living expenses.\n",
    "\n",
    "__You are fully responsible for any investment or trading decisions you make__. Such decisions should be based solely on your evaluation of your financial circumstances, investment or trading objectives, risk tolerance, and liquidity needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acd24af-f7dd-4801-8341-a3375f2c0ebc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.3",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
